[**ğŸ‡¨ğŸ‡³ä¸­æ–‡**](https://github.com/shibing624/parrots/blob/master/README.md) | [**ğŸŒEnglish**](https://github.com/shibing624/parrots/blob/master/README_EN.md) | [**ğŸ“–æ–‡æ¡£/Docs**](https://github.com/shibing624/parrots/wiki) | [**ğŸ¤–æ¨¡å‹/Models**](https://huggingface.co/shibing624) 

<div align="center">
    <a href="https://github.com/shibing624/parrots">
    <img src="https://github.com/shibing624/parrots/blob/master/docs/parrots_icon.png" alt="Logo" height="156">
    </a>
    <br/>
    <a href="https://huggingface.co/spaces/shibing624/parrots" target="_blank"> Online Demo </a>
    <br/>
    <img width="70%" src="https://github.com/shibing624/parrots/blob/master/docs/screenshot.png">
</div>


-----------------

# Parrots: ASR and TTS toolkit
[![PyPI version](https://badge.fury.io/py/parrots.svg)](https://badge.fury.io/py/parrots)
[![Downloads](https://static.pepy.tech/badge/parrots)](https://pepy.tech/project/parrots)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](CONTRIBUTING.md)
[![GitHub contributors](https://img.shields.io/github/contributors/shibing624/parrots.svg)](https://github.com/shibing624/parrots/graphs/contributors)
[![License Apache 2.0](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)
[![python_vesion](https://img.shields.io/badge/Python-3.7%2B-green.svg)](requirements.txt)
[![GitHub issues](https://img.shields.io/github/issues/shibing624/parrots.svg)](https://github.com/shibing624/parrots/issues)
[![Wechat Group](https://img.shields.io/badge/wechat-group-green.svg?logo=wechat)](#Contact)

## Introduction
Parrots, Automatic Speech Recognition(**ASR**), Text-To-Speech(**TTS**) toolkit, support Chinese, English, Japanese, etc.

**parrots**å®ç°äº†è¯­éŸ³è¯†åˆ«å’Œè¯­éŸ³åˆæˆæ¨¡å‹ä¸€é”®è°ƒç”¨ï¼Œå¼€ç®±å³ç”¨ï¼Œæ”¯æŒä¸­è‹±æ–‡ã€‚

## Features
1. ASRï¼šåŸºäº`distilwhisper`å®ç°çš„ä¸­æ–‡è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰æ¨¡å‹ï¼Œæ”¯æŒä¸­ã€è‹±ç­‰å¤šç§è¯­è¨€
2. TTSï¼šåŸºäº`GPT-SoVITS`è®­ç»ƒçš„è¯­éŸ³åˆæˆï¼ˆTTSï¼‰æ¨¡å‹ï¼Œæ”¯æŒä¸­ã€è‹±ã€æ—¥ç­‰å¤šç§è¯­è¨€



## Install
```shell
pip install torch # or conda install pytorch
pip install -r requirements.txt
pip install parrots
```
or
```shell
pip install torch # or conda install pytorch
git clone https://github.com/shibing624/parrots.git
cd parrots
python setup.py install
```

## Demo
HF Demo: https://huggingface.co/spaces/shibing624/parrots
Official Demo: https://www.mulanai.com/product/asr/

## Usage
### ASR
example: [examples/demo_asr.py](https://github.com/shibing624/parrots/blob/master/examples/demo_asr.py)
```python
import os
import sys

sys.path.append('..')
from parrots import SpeechRecognition

pwd_path = os.path.abspath(os.path.dirname(__file__))

if __name__ == '__main__':
    m = SpeechRecognition()
    r = m.recognize_speech_from_file(os.path.join(pwd_path, 'tushuguan.wav'))
    print('[æç¤º] è¯­éŸ³è¯†åˆ«ç»“æœï¼š', r)

```

output:
```
{'text': 'åŒ—äº¬å›¾ä¹¦é¦†'}
```

### TTS(Speech Synthesis)
example: [examples/demo_tts.py](https://github.com/shibing624/parrots/blob/master/examples/demo_tts.py)
```python
import sys

sys.path.append('..')
from parrots import TextToSpeech
m = TextToSpeech(
    speaker_model_path="shibing624/parrots-gpt-sovits-speaker-maimai",
    speaker_name="MaiMai",
    device="cpu",
    half=False
)
m.predict(
    text="ä½ å¥½ï¼Œæ¬¢è¿æ¥åŒ—äº¬ã€‚welcome to the city.",
    text_language="auto",
    output_path="output_audio.wav"
)
```

output:
```
Save audio to output_audio.wav
```


### å‘½ä»¤è¡Œæ¨¡å¼ï¼ˆCLIï¼‰

æ”¯æŒé€šè¿‡å‘½ä»¤è¡Œæ–¹å¼æ‰§è¡ŒARSå’ŒTTSä»»åŠ¡ï¼Œä»£ç ï¼š[cli.py](https://github.com/shibing624/parrots/blob/master/parrots/cli.py)

```
> parrots -h                                    

NAME
    parrots

SYNOPSIS
    parrots COMMAND

COMMANDS
    COMMAND is one of the following:

     asr
       Entry point of asr, recognize speech from file

     tts
       Entry point of tts, generate speech audio from text

```

runï¼š

```shell
pip install parrots -U
# asr example
parrots asr -h
parrots asr examples/tushuguan.wav

# tts example
parrots tts -h
parrots tts "ä½ å¥½ï¼Œæ¬¢è¿æ¥åŒ—äº¬ã€‚welcome to the city." output_audio.wav
```

- `asr`ã€`tts`æ˜¯äºŒçº§å‘½ä»¤ï¼Œasræ˜¯è¯­éŸ³è¯†åˆ«ï¼Œttsæ˜¯è¯­éŸ³åˆæˆï¼Œé»˜è®¤ä½¿ç”¨çš„æ¨¡å‹æ˜¯ä¸­æ–‡æ¨¡å‹
- å„äºŒçº§å‘½ä»¤ä½¿ç”¨æ–¹æ³•è§`parrots asr -h`
- ä¸Šé¢ç¤ºä¾‹ä¸­`examples/tushuguan.wav`æ˜¯`asr`æ–¹æ³•çš„`audio_file_path`å‚æ•°ï¼Œè¾“å…¥çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆrequiredï¼‰


## Contact

- Issue(å»ºè®®)ï¼š[![GitHub issues](https://img.shields.io/github/issues/shibing624/parrots.svg)](https://github.com/shibing624/parrots/issues)
- é‚®ä»¶æˆ‘ï¼šxuming: xuming624@qq.com
- å¾®ä¿¡æˆ‘ï¼šåŠ æˆ‘*å¾®ä¿¡å·ï¼šxuming624*, è¿›Python-NLPäº¤æµç¾¤ï¼Œå¤‡æ³¨ï¼š*å§“å-å…¬å¸å-NLP*

<img src="docs/wechat.jpeg" width="200" />


## Citation

å¦‚æœä½ åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†parrotsï¼Œè¯·æŒ‰å¦‚ä¸‹æ ¼å¼å¼•ç”¨ï¼š

```latex
@misc{parrots,
  title={parrots: ASR and TTS Tool},
  author={Ming Xu},
  year={2024},
  howpublished={\url{https://github.com/shibing624/parrots}},
}
```

## License


æˆæƒåè®®ä¸º [The Apache License 2.0](/LICENSE)ï¼Œå¯å…è´¹ç”¨åšå•†ä¸šç”¨é€”ã€‚è¯·åœ¨äº§å“è¯´æ˜ä¸­é™„åŠ parrotsçš„é“¾æ¥å’Œæˆæƒåè®®ã€‚


## Contribute
é¡¹ç›®ä»£ç è¿˜å¾ˆç²—ç³™ï¼Œå¦‚æœå¤§å®¶å¯¹ä»£ç æœ‰æ‰€æ”¹è¿›ï¼Œæ¬¢è¿æäº¤å›æœ¬é¡¹ç›®ï¼Œåœ¨æäº¤ä¹‹å‰ï¼Œæ³¨æ„ä»¥ä¸‹ä¸¤ç‚¹ï¼š

 - åœ¨`tests`æ·»åŠ ç›¸åº”çš„å•å…ƒæµ‹è¯•
 - ä½¿ç”¨`python -m pytest`æ¥è¿è¡Œæ‰€æœ‰å•å…ƒæµ‹è¯•ï¼Œç¡®ä¿æ‰€æœ‰å•æµ‹éƒ½æ˜¯é€šè¿‡çš„

ä¹‹åå³å¯æäº¤PRã€‚


## Reference
#### ASR
- [EAT: Enhanced ASR-TTS for Self-supervised Speech Recognition](https://arxiv.org/abs/2104.07474)
- [PaddlePaddle/PaddleSpeech](https://github.com/PaddlePaddle/PaddleSpeech)
- [NVIDIA/NeMo](https://github.com/NVIDIA/NeMo)
#### TTS(Speech Synthesis)
- [coqui-ai/TTS](https://github.com/coqui-ai/TTS)
- [keonlee9420/Expressive-FastSpeech2](https://github.com/keonlee9420/Expressive-FastSpeech2)
- [TensorSpeech/TensorflowTTS](https://github.com/TensorSpeech/TensorflowTTS)
- [RVC-Boss/GPT-SoVITS](https://github.com/RVC-Boss/GPT-SoVITS)
